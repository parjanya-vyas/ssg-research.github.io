---
layout: default
permalink: /mlsec/interactions
nav: false
horizontal: false
title: Unintended Interactions among ML Risks and Defenses
---


# Unintended Interactions among ML Risks and Defenses

## Background 

Machine learning models are susceptible to a wide range of risks to security, privacy, and fairness. 
Several defenses have been proposed to mitigate these risks. 
However, defending against a specific risk can result in an unintended increase (or decrease) in susceptibility to other risks. 
Similarly when defenses against multiple risks are applied to a machine learning model, there could be conflicting interactions among among them.
This [blog article](https://crysp.uwaterloo.ca/ssg/blog/2024/05/unintended-interactions-among-ml.html) provides additional context for this work.

## Conference/journal paper publications

- Vasisht Duddu, Sebastian Szyller, N. Asokan: **SoK: Unintended Interactions among Machine Learning Defenses and Risks.** [IEEE S&P 2024](https://sp2024.ieee-security.org/). arXiv preprint [arXiv:2312.04542](https://arxiv.org/abs/2312.04542). (Distinguished paper award)
- Sebastian Szyller, N. Asokan: **Conflicting Interactions Among Protection Mechanisms for Machine Learning Models**. [AAAI 2023](https://aaai-23.aaai.org). arXiv preprint [arXiv:2207.01991](https://arxiv.org/abs/2207.01991)

## Software Library

- **Amulet: A Library for Evaluating interactions among Machine Learning Risks and Defeneses** [Code](https://github.com/ssg-research/amulet)

## Posters

- **SoK: Unintended Interactions among Machine Learning Defenses and Risks.** [pdf](../../assets/pdf/mlsec/sok_poster.pdf)

## Talks

- SoK: Unintended Interactions among Machine Learning Defenses and Risks. [pdf](../../assets/pdf/mlsec/SoK.pdf) [talk](https://youtu.be/W6ilf0Sba5U)
- Conflicting Interactions Among Protection Mechanisms for Machine Learning Models. [pdf](../../assets/pdf/mlsec/MLConfGoals-master.pdf)

## Source code

- [GitHub source code for Amulet](https://github.com/ssg-research/amulet)
- [GitHub source code for SoK](https://github.com/ssg-research/sok-unintended-interactions)
- [GitHub source code for Conflicting Interactions](https://github.com/ssg-research/conflicts-in-ml-protection-mechanisms)
